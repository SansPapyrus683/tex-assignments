\documentclass[12pt]{article}

\input{../kz}

\lhead{406-196-414}
\rhead{CS 180}

\newcommand{\what}{\stackrel{?}=}

\begin{document}

\section{Cell Phone Coverage}

\subsection{Algorithm}

\begin{algorithmic}[1]
    \State Sort $A$
    \State $\texttt{lastHouse} \gets 0$
    \State $\texttt{stations} \gets \{\}$
    \For{$i = 1, \cdots, n$}
        \If{$A[i] > A[\texttt{lastHouse}] + 8$}
        \State $\texttt{stations} \gets \texttt{stations} \cup \{A[\texttt{lastHouse}] + 4\}$
        \State $\texttt{lastHouse} \gets i$
        \EndIf
    \EndFor
    \LComment{When loop terminates we're still "building" a station}
    \State $\texttt{stations} \gets \texttt{stations} \cup \{A[\texttt{lastHouse}] + 4\}$
    \State \Return \texttt{minStations}
\end{algorithmic}

\subsection{Correctness}

It is clear that this algorithm terminates.

By construction, this algorithm is guranteed to output a sufficient number
of stations, since it makes sure that every house is covered.
it remains to prove that this is the minimum number of stations needed.

BWOC let there be some $O=\{p_1', p_2', \cdots, p_n'\}$ that's smaller
than the set of base stations our algorithm calculates $S=\{p_1, p_2, \cdots, p_m\}$.
Assume that the two are sorted by position.

Let us prove by induction that $p_i \ge p_i'$.
For a base case, $p_1 \ge p_1'$ since our algorithm
places the first base station as far to the right of the first house as possible.
Any other possible base station that covers the first house
must be placed to the left of $p_1$.

We know assume $p_i \ge p_i'$ and WTS $p_{i+1} \ge p_{i+1}'$.
Consider the first house that isn't covered by $p_i$.
By our inductive hypothesis, we know $O$ hasn't covered this house yet either.
Again, since our algorithm tries to place $p_{i+1}$ as far to the right as possible,
any other station that covers this house must not be to the right of it.
Thus, $p_{i+1} \ge p_{i+1}'$, and the inductive step is complete.

Now let $n < m$.
If this was the case, then there must be some house that isn't covered by $O$
since $p_m$ must cover a nonzero number of houses and $p_n \ge p_n'$,
which contradicts that $O$ is a feasiable covering.
Thus, $n=m$ and our solution is optimal. $\square$

\subsection{Complexity}

Sorting $A$ takes $O(n \log n)$ time, and the for loop completes in $O(n)$
iterations, with each iteration taking constant time.
The total time complexity is easily seen to be $\boxed{O(n \log n)}$.

\pagebreak

\section{Graph Degree}

\subsection{Algorithm}

\begin{algorithmic}[1]
    \If{$\sum_{i=1}^n d_i > \frac{n(n-2)}{2}$ or is odd}
        \State \Return impossible
    \EndIf

    \item[]
    \State $\texttt{todo} \gets []$
    \State $E \gets \{\}$
    \For{$i = 2, 4, \cdots, |\texttt{todo}|$}
        \State $E \gets E \cup \{(\texttt{todo}[i-1], \texttt{todo}[i])\}$
    \EndFor

    \item[]
    \State \Return graph with vertices $1$ through $n$ and edges $E$
\end{algorithmic}

\subsection{Correctness}

It is clear that this algorithm terminates.

By construction, the algorithm outputs a graph with the given set of degrees.
It remains to prove that it'll always output such a set if one is possible.
By the \href{https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Gallai_theorem}{Erdos-Gallai Theorem},
a graph with the given $d_i$ can exist iff the sum of all degress is even and
\[\sum_{i=1}^{k} d_i \le k(k-1)+\sum_{i=k+1}^{n} \min(d_i, k)\]
for all $i$ from $1$ to $n$.

The algorithm checks for the even condition since it only adds edges in pairs.
If the sum of degrees was odd, we'd always hit a situation where a degree
runs out of nodes to connect to or tries to connect to a node with $0$ remaining connections.

Similarly, due to how we iterate through the degrees from largest to smallest,
the algorithm guarantees that the main condition is satisfied. $\square$

\pagebreak

\section{Triathlon}

\subsection{Algorithm}

Let $s_i$, $r_i$, and $b_i$ be the swimming time, running time,
and biking time of each camper.

\begin{algorithmic}[1]
    \State Sort campers by in decreasing order by $r_i+b_i$
    \LComment{The question asks for the order itself, not the completion time.}
    \State \Return the sorted campers
\end{algorithmic}

\subsection{Correctness}

It's easy to see that this algorithm terminates.

We proceed with an exchange argument.
For convenience, let $l_i=r_i+b_i$.
Suppose the optimal order of campers $c$ has $c_i$ and $c_j$ s.t. $l_{c_i} < l_{c_j}$.

Swapping these two, the completion time at index $i$ changes from
\[\left(\sum_{k=1}^{i} l_{c_k}\right)+l_{c_i} \to \left(\sum_{k=1}^{i-1} s_{c_k}\right)+s_{c_j}+l_{c_j}\]
and the one at index $j$ changes from
\[\left(\sum_{k=1}^{j} s_{c_k}\right)+l_{c_j} \to \left(\sum_{k=1}^{j} s_{c_k}\right)+l_{c_i}\]

Let the old values be $a$ and $b$ and the new values be $a'$ and $b'$.
By inspection, $a' \le b$ and $b'<b$, so this swapped order of campers
achieves a completion time that is no greater than the time achieved by the supposed optimal permutation.

Swapping all pairs of $i$ and $j$ s.t. $l_{c_i} < l_{c_j}$, we get the
sorted order that our algorithm originally defines.
Thus, our algorithm produces the order with minimal completion time. $\square$

\subsection{Complexity}

All the algorithm does is sort the campers, so it runs in $\boxed{O(n \log n)}$.

\pagebreak

\section{Video Streams}

\subsection{Valid Condition}

Unfortunately, the given assertion isn't true.
Consider
\[(b_1, t_1) = (1000, 1), (b_2, t_2)=(3000, 1), r=2000\]
We can make this valid by putting the first stream first and the second stream second.

\subsection{Algorithm}

\begin{algorithmic}[1]
    \State Sort streams from smallest $\frac{b_i}{t_i}$ to largest.
    \State $\texttt{storedBits} \gets 0$
    \For{$i = 1, \cdots, n$}
        \State $\texttt{storedBits} \gets \texttt{storedBits} + t_i (r - b_i)$
        \If{$\texttt{storedBits} < 0$}
            \State \Return no valid schedule
        \EndIf
    \EndFor
    \State \Return valid schedule
\end{algorithmic}

\subsection{Correctness}

It's easy to see that this algorithm terminates.

Say there is a permutation of the video streams that is under the ratelimit.
We'll prove that we can reach the sorted order the algorithm uses while staying under the limit.

Notice that to reach our order, we will \textit{never} have to swap
two streams $i$ and $j$ where $i < j$ and $\frac{b_i}{t_i} < \frac{b_j}{t_j}$.
We only have to consider when $\frac{b_i}{t_i} \ge \frac{b_j}{t_j}$.
In this case, we frontload the stream with the lesser bits per second,
so even though the total amount of bits at the end is the same, the
prefix sum of the bits is guaranteed to be no greater than the last
prefix sum elementwise.

Thus, after making some number of these swaps, we can see that
our sorted order is guaranteed to be valid if there exists any valid schedule.

OTOH, if there is no valid schedule, then clearly
our selected permutation won't be a valid schedule, and the algorithm
will correctly return that no valid schedule exists. $\square$

\subsection{Complexity}

The algorithm sorts the streams then does an elementary for loop, so it runs in $\boxed{O(n \log n)}$.

\pagebreak

\section{Bottleneck Rates}

\subsection{Algorithm}

\begin{algorithmic}[1]
    \State Sort edges from \textit{largest} to smallest.
    \State Run Kruskal's on those edges.
    \Comment{Yep, that's literally it.}
\end{algorithmic}

\subsection{Correctness}

It's easy to see that this algorithm terminates.

The proof of correctness is done by induction.
We assert that at each step in the algorithm, each tree in the forest
Kruskal's has the best bottleneck rates for all pairs of nodes that
lie within it.

The base case is trivial, as at the start each node is its own "tree".
We now want to show that adding an edge according to the algorithm's
sorting order won't change this invariant.

BWOC suppose there exist nodes $u$ and $v$ that are in different components
$\mathcal{C}_1$ and $\mathcal{C}_2$, and the edge we add isn't the one on the best bottleneck path.
Suppose there's some other edge we missed that's actually the better one.

Since we sorted the edges from largest weight to smallest, any new edge we add
is guaranteed to be equal to the minimum value along any paths from $\mathcal{C}_1$ to $\mathcal{C}_2$.
By the same reason, not considering this alternate edge would've meant that
it had a weight that was no greater than the one we actually added.
However, this means that the bottleneck rate of this supposed "better path"
is actually just as bad, if not worse, than the one we actually added.
Contradiction.

With this, the inductive step is shown and our algorithm has been proven. $\square$

\subsection{Complexity}

$\boxed{O(|E| \log |E|)}$ time, since our algorithm just runs Kruskal's with a tiny modification.

\pagebreak

\section{Squaring Edge Weights}

\subsection{Shortest Path Invariance}

False. Consider a graph with 3 nodes and the following edges:
\begin{itemize}[nolistsep]
    \item One from $0$ to $2$ of weight 10
    \item One from $0$ to $1$ of weight 6
    \item One from $1$ to $2$ of weight 6
\end{itemize}
While the shortest path in this goes from $0$ to $2$ directly,
after squaring the edge weights it would be more optimal
to go to $1$ then to $2$, as that only costs $6^2+6^2=72$ units.

\subsection{MST Invariance}

Squaring all the edge weights preserves their sorted order in terms
of weight, since $a < b$ implies $a^2 < b^2$.
If Kruskal's algorithm gets the same edges in the same order,
it'll output the same MST regardless of the actual weights of the edges.
Thus, $T$ wouldn't change if we squared all the edge weights. $\square$

\end{document}
